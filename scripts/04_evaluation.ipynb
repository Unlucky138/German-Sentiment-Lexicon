{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5974aed",
   "metadata": {},
   "source": [
    "# Lexikonbasierte Evaluation \n",
    "### Referenz GerVADER \n",
    "- ### https://github.com/KarstenAMF/GerVADER/tree/master\n",
    "- ### https://github.com/KarstenAMF/GerVADER/blob/master/vaderSentimentGER.py\n",
    "\n",
    "-----\n",
    "\n",
    "- **Minimaler Normalizer/Tokenizer**  \n",
    "  (lowercase + einfache Tokenisierung)\n",
    "\n",
    "- **Kleiner Stopwort-Filter**  \n",
    "  (nur hÃ¤ufigste FunktionswÃ¶rter: Artikel, PrÃ¤positionen, Pronomen)\n",
    "\n",
    "- **Kleine Emoji-Sentimentliste**  \n",
    "  (ca. 15 Emojis/Emoticons siehe GerVADER)\n",
    "\n",
    "- **GerVADER-Ã¤hnliche Heuristiken**  \n",
    "  - Intensifier / Downtoner  \n",
    "  - Negation (Scope)\n",
    "\n",
    "- **Statische Thresholds**\n",
    "  - Weighted Average: Â±0.15  *(breitere Score-Verteilung)*  \n",
    "  - Bayesian SentiMerge: Â±0.10  *(Shrinkage â†’ kompakter um 0)*\n",
    "\n",
    "- **Auswertung**\n",
    "  - VollstÃ¤ndige Kennzahlen je Klasse (Precision / Recall / F1 + Support)  \n",
    "  - Accuracy  \n",
    "  - Macro-F1\n",
    "\n",
    "- **Showcase**  \n",
    "    - Konkretes Beispiel aus jedem Datensatz (SB10k, GermEval2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3222dc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Class</th>\n",
       "      <th>Support</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AccuracyOverall</th>\n",
       "      <th>MacroF1</th>\n",
       "      <th>pos_thr</th>\n",
       "      <th>neg_thr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>ALPIN</td>\n",
       "      <td>negative</td>\n",
       "      <td>6911</td>\n",
       "      <td>0.360825</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>0.029159</td>\n",
       "      <td>0.605428</td>\n",
       "      <td>0.294234</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>ALPIN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>17747</td>\n",
       "      <td>0.675379</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.762923</td>\n",
       "      <td>0.605428</td>\n",
       "      <td>0.294234</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>ALPIN</td>\n",
       "      <td>positive</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.069589</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.090621</td>\n",
       "      <td>0.605428</td>\n",
       "      <td>0.294234</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>ANGST</td>\n",
       "      <td>negative</td>\n",
       "      <td>6911</td>\n",
       "      <td>0.426181</td>\n",
       "      <td>0.125307</td>\n",
       "      <td>0.193671</td>\n",
       "      <td>0.458852</td>\n",
       "      <td>0.311815</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>ANGST</td>\n",
       "      <td>neutral</td>\n",
       "      <td>17747</td>\n",
       "      <td>0.674608</td>\n",
       "      <td>0.598355</td>\n",
       "      <td>0.634197</td>\n",
       "      <td>0.458852</td>\n",
       "      <td>0.311815</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>ANGST</td>\n",
       "      <td>positive</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.063620</td>\n",
       "      <td>0.348052</td>\n",
       "      <td>0.107577</td>\n",
       "      <td>0.458852</td>\n",
       "      <td>0.311815</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>AffDict</td>\n",
       "      <td>negative</td>\n",
       "      <td>6911</td>\n",
       "      <td>0.358621</td>\n",
       "      <td>0.075242</td>\n",
       "      <td>0.124387</td>\n",
       "      <td>0.511757</td>\n",
       "      <td>0.304942</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>AffDict</td>\n",
       "      <td>neutral</td>\n",
       "      <td>17747</td>\n",
       "      <td>0.670820</td>\n",
       "      <td>0.703781</td>\n",
       "      <td>0.686905</td>\n",
       "      <td>0.511757</td>\n",
       "      <td>0.304942</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>AffDict</td>\n",
       "      <td>positive</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.064774</td>\n",
       "      <td>0.257792</td>\n",
       "      <td>0.103534</td>\n",
       "      <td>0.511757</td>\n",
       "      <td>0.304942</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>AffNorms</td>\n",
       "      <td>negative</td>\n",
       "      <td>6911</td>\n",
       "      <td>0.472857</td>\n",
       "      <td>0.047895</td>\n",
       "      <td>0.086979</td>\n",
       "      <td>0.514887</td>\n",
       "      <td>0.299153</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>AffNorms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>17747</td>\n",
       "      <td>0.655422</td>\n",
       "      <td>0.713811</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>0.514887</td>\n",
       "      <td>0.299153</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>AffNorms</td>\n",
       "      <td>positive</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.079417</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.127108</td>\n",
       "      <td>0.514887</td>\n",
       "      <td>0.299153</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>Bayesian SentiMerge</td>\n",
       "      <td>negative</td>\n",
       "      <td>6911</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>0.048329</td>\n",
       "      <td>0.088011</td>\n",
       "      <td>0.617719</td>\n",
       "      <td>0.331793</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>Bayesian SentiMerge</td>\n",
       "      <td>neutral</td>\n",
       "      <td>17747</td>\n",
       "      <td>0.676568</td>\n",
       "      <td>0.876599</td>\n",
       "      <td>0.763702</td>\n",
       "      <td>0.617719</td>\n",
       "      <td>0.331793</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>Bayesian SentiMerge</td>\n",
       "      <td>positive</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.115644</td>\n",
       "      <td>0.189610</td>\n",
       "      <td>0.143665</td>\n",
       "      <td>0.617719</td>\n",
       "      <td>0.331793</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>GPC</td>\n",
       "      <td>negative</td>\n",
       "      <td>6911</td>\n",
       "      <td>0.362287</td>\n",
       "      <td>0.455650</td>\n",
       "      <td>0.403640</td>\n",
       "      <td>0.374990</td>\n",
       "      <td>0.329138</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>GPC</td>\n",
       "      <td>neutral</td>\n",
       "      <td>17747</td>\n",
       "      <td>0.700595</td>\n",
       "      <td>0.338592</td>\n",
       "      <td>0.456542</td>\n",
       "      <td>0.374990</td>\n",
       "      <td>0.329138</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>GPC</td>\n",
       "      <td>positive</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.074588</td>\n",
       "      <td>0.432468</td>\n",
       "      <td>0.127233</td>\n",
       "      <td>0.374990</td>\n",
       "      <td>0.329138</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>PolArt</td>\n",
       "      <td>negative</td>\n",
       "      <td>6911</td>\n",
       "      <td>0.412286</td>\n",
       "      <td>0.302995</td>\n",
       "      <td>0.349291</td>\n",
       "      <td>0.453737</td>\n",
       "      <td>0.361707</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>PolArt</td>\n",
       "      <td>neutral</td>\n",
       "      <td>17747</td>\n",
       "      <td>0.711194</td>\n",
       "      <td>0.512988</td>\n",
       "      <td>0.596046</td>\n",
       "      <td>0.453737</td>\n",
       "      <td>0.361707</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>PolArt</td>\n",
       "      <td>positive</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.082832</td>\n",
       "      <td>0.447403</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.453737</td>\n",
       "      <td>0.361707</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>SentiWS</td>\n",
       "      <td>negative</td>\n",
       "      <td>6911</td>\n",
       "      <td>0.433194</td>\n",
       "      <td>0.209232</td>\n",
       "      <td>0.282174</td>\n",
       "      <td>0.592030</td>\n",
       "      <td>0.386125</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>SentiWS</td>\n",
       "      <td>neutral</td>\n",
       "      <td>17747</td>\n",
       "      <td>0.699165</td>\n",
       "      <td>0.773426</td>\n",
       "      <td>0.734423</td>\n",
       "      <td>0.592030</td>\n",
       "      <td>0.386125</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>SentiWS</td>\n",
       "      <td>positive</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.104709</td>\n",
       "      <td>0.219481</td>\n",
       "      <td>0.141779</td>\n",
       "      <td>0.592030</td>\n",
       "      <td>0.386125</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>negative</td>\n",
       "      <td>6911</td>\n",
       "      <td>0.432279</td>\n",
       "      <td>0.175951</td>\n",
       "      <td>0.250103</td>\n",
       "      <td>0.525193</td>\n",
       "      <td>0.356046</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>neutral</td>\n",
       "      <td>17747</td>\n",
       "      <td>0.672681</td>\n",
       "      <td>0.678594</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.525193</td>\n",
       "      <td>0.356046</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GermEval2017</td>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>positive</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.142410</td>\n",
       "      <td>0.525193</td>\n",
       "      <td>0.356046</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>ALPIN</td>\n",
       "      <td>negative</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.074336</td>\n",
       "      <td>0.124444</td>\n",
       "      <td>0.574371</td>\n",
       "      <td>0.379527</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>ALPIN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4629</td>\n",
       "      <td>0.637215</td>\n",
       "      <td>0.808598</td>\n",
       "      <td>0.712749</td>\n",
       "      <td>0.574371</td>\n",
       "      <td>0.379527</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>ALPIN</td>\n",
       "      <td>positive</td>\n",
       "      <td>1717</td>\n",
       "      <td>0.337916</td>\n",
       "      <td>0.271986</td>\n",
       "      <td>0.301388</td>\n",
       "      <td>0.574371</td>\n",
       "      <td>0.379527</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>ANGST</td>\n",
       "      <td>negative</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.332418</td>\n",
       "      <td>0.214159</td>\n",
       "      <td>0.260495</td>\n",
       "      <td>0.521268</td>\n",
       "      <td>0.430056</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>ANGST</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4629</td>\n",
       "      <td>0.659139</td>\n",
       "      <td>0.611579</td>\n",
       "      <td>0.634469</td>\n",
       "      <td>0.521268</td>\n",
       "      <td>0.430056</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>ANGST</td>\n",
       "      <td>positive</td>\n",
       "      <td>1717</td>\n",
       "      <td>0.335915</td>\n",
       "      <td>0.479907</td>\n",
       "      <td>0.395204</td>\n",
       "      <td>0.521268</td>\n",
       "      <td>0.430056</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>AffDict</td>\n",
       "      <td>negative</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.315682</td>\n",
       "      <td>0.137168</td>\n",
       "      <td>0.191240</td>\n",
       "      <td>0.551231</td>\n",
       "      <td>0.402561</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>AffDict</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4629</td>\n",
       "      <td>0.643587</td>\n",
       "      <td>0.734932</td>\n",
       "      <td>0.686233</td>\n",
       "      <td>0.551231</td>\n",
       "      <td>0.402561</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>AffDict</td>\n",
       "      <td>positive</td>\n",
       "      <td>1717</td>\n",
       "      <td>0.331960</td>\n",
       "      <td>0.328480</td>\n",
       "      <td>0.330211</td>\n",
       "      <td>0.551231</td>\n",
       "      <td>0.402561</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>AffNorms</td>\n",
       "      <td>negative</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.486381</td>\n",
       "      <td>0.110619</td>\n",
       "      <td>0.180245</td>\n",
       "      <td>0.645800</td>\n",
       "      <td>0.474091</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>AffNorms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4629</td>\n",
       "      <td>0.689722</td>\n",
       "      <td>0.846619</td>\n",
       "      <td>0.760159</td>\n",
       "      <td>0.645800</td>\n",
       "      <td>0.474091</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>AffNorms</td>\n",
       "      <td>positive</td>\n",
       "      <td>1717</td>\n",
       "      <td>0.510085</td>\n",
       "      <td>0.456610</td>\n",
       "      <td>0.481868</td>\n",
       "      <td>0.645800</td>\n",
       "      <td>0.474091</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>Bayesian SentiMerge</td>\n",
       "      <td>negative</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.460922</td>\n",
       "      <td>0.203540</td>\n",
       "      <td>0.282382</td>\n",
       "      <td>0.621322</td>\n",
       "      <td>0.496540</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>Bayesian SentiMerge</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4629</td>\n",
       "      <td>0.693279</td>\n",
       "      <td>0.771009</td>\n",
       "      <td>0.730081</td>\n",
       "      <td>0.621322</td>\n",
       "      <td>0.496540</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>Bayesian SentiMerge</td>\n",
       "      <td>positive</td>\n",
       "      <td>1717</td>\n",
       "      <td>0.462548</td>\n",
       "      <td>0.492720</td>\n",
       "      <td>0.477157</td>\n",
       "      <td>0.621322</td>\n",
       "      <td>0.496540</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>GPC</td>\n",
       "      <td>negative</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.236152</td>\n",
       "      <td>0.430088</td>\n",
       "      <td>0.304893</td>\n",
       "      <td>0.409577</td>\n",
       "      <td>0.389655</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>GPC</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4629</td>\n",
       "      <td>0.650951</td>\n",
       "      <td>0.354936</td>\n",
       "      <td>0.459388</td>\n",
       "      <td>0.409577</td>\n",
       "      <td>0.389655</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>GPC</td>\n",
       "      <td>positive</td>\n",
       "      <td>1717</td>\n",
       "      <td>0.322391</td>\n",
       "      <td>0.543390</td>\n",
       "      <td>0.404684</td>\n",
       "      <td>0.409577</td>\n",
       "      <td>0.389655</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>PolArt</td>\n",
       "      <td>negative</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.283419</td>\n",
       "      <td>0.390265</td>\n",
       "      <td>0.328369</td>\n",
       "      <td>0.469369</td>\n",
       "      <td>0.437767</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>PolArt</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4629</td>\n",
       "      <td>0.696220</td>\n",
       "      <td>0.425794</td>\n",
       "      <td>0.528418</td>\n",
       "      <td>0.469369</td>\n",
       "      <td>0.437767</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>PolArt</td>\n",
       "      <td>positive</td>\n",
       "      <td>1717</td>\n",
       "      <td>0.355131</td>\n",
       "      <td>0.638905</td>\n",
       "      <td>0.456513</td>\n",
       "      <td>0.469369</td>\n",
       "      <td>0.437767</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>SentiWS</td>\n",
       "      <td>negative</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.293320</td>\n",
       "      <td>0.268142</td>\n",
       "      <td>0.280166</td>\n",
       "      <td>0.578250</td>\n",
       "      <td>0.467741</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>SentiWS</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4629</td>\n",
       "      <td>0.669539</td>\n",
       "      <td>0.721754</td>\n",
       "      <td>0.694667</td>\n",
       "      <td>0.578250</td>\n",
       "      <td>0.467741</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>SentiWS</td>\n",
       "      <td>positive</td>\n",
       "      <td>1717</td>\n",
       "      <td>0.467309</td>\n",
       "      <td>0.395457</td>\n",
       "      <td>0.428391</td>\n",
       "      <td>0.578250</td>\n",
       "      <td>0.467741</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>negative</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.230088</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.616105</td>\n",
       "      <td>0.486119</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4629</td>\n",
       "      <td>0.684744</td>\n",
       "      <td>0.788291</td>\n",
       "      <td>0.732878</td>\n",
       "      <td>0.616105</td>\n",
       "      <td>0.486119</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SB10k</td>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>positive</td>\n",
       "      <td>1717</td>\n",
       "      <td>0.469993</td>\n",
       "      <td>0.405941</td>\n",
       "      <td>0.435625</td>\n",
       "      <td>0.616105</td>\n",
       "      <td>0.486119</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dataset              Variant     Class  Support  Precision    Recall  \\\n",
       "0   GermEval2017                ALPIN  negative     6911   0.360825  0.015193   \n",
       "1   GermEval2017                ALPIN   neutral    17747   0.675379  0.876543   \n",
       "2   GermEval2017                ALPIN  positive     1540   0.069589  0.129870   \n",
       "3   GermEval2017                ANGST  negative     6911   0.426181  0.125307   \n",
       "4   GermEval2017                ANGST   neutral    17747   0.674608  0.598355   \n",
       "5   GermEval2017                ANGST  positive     1540   0.063620  0.348052   \n",
       "6   GermEval2017              AffDict  negative     6911   0.358621  0.075242   \n",
       "7   GermEval2017              AffDict   neutral    17747   0.670820  0.703781   \n",
       "8   GermEval2017              AffDict  positive     1540   0.064774  0.257792   \n",
       "9   GermEval2017             AffNorms  negative     6911   0.472857  0.047895   \n",
       "10  GermEval2017             AffNorms   neutral    17747   0.655422  0.713811   \n",
       "11  GermEval2017             AffNorms  positive     1540   0.079417  0.318182   \n",
       "12  GermEval2017  Bayesian SentiMerge  negative     6911   0.491900  0.048329   \n",
       "13  GermEval2017  Bayesian SentiMerge   neutral    17747   0.676568  0.876599   \n",
       "14  GermEval2017  Bayesian SentiMerge  positive     1540   0.115644  0.189610   \n",
       "15  GermEval2017                  GPC  negative     6911   0.362287  0.455650   \n",
       "16  GermEval2017                  GPC   neutral    17747   0.700595  0.338592   \n",
       "17  GermEval2017                  GPC  positive     1540   0.074588  0.432468   \n",
       "18  GermEval2017               PolArt  negative     6911   0.412286  0.302995   \n",
       "19  GermEval2017               PolArt   neutral    17747   0.711194  0.512988   \n",
       "20  GermEval2017               PolArt  positive     1540   0.082832  0.447403   \n",
       "21  GermEval2017              SentiWS  negative     6911   0.433194  0.209232   \n",
       "22  GermEval2017              SentiWS   neutral    17747   0.699165  0.773426   \n",
       "23  GermEval2017              SentiWS  positive     1540   0.104709  0.219481   \n",
       "24  GermEval2017     Weighted Average  negative     6911   0.432279  0.175951   \n",
       "25  GermEval2017     Weighted Average   neutral    17747   0.672681  0.678594   \n",
       "26  GermEval2017     Weighted Average  positive     1540   0.091208  0.324675   \n",
       "27         SB10k                ALPIN  negative     1130   0.381818  0.074336   \n",
       "28         SB10k                ALPIN   neutral     4629   0.637215  0.808598   \n",
       "29         SB10k                ALPIN  positive     1717   0.337916  0.271986   \n",
       "30         SB10k                ANGST  negative     1130   0.332418  0.214159   \n",
       "31         SB10k                ANGST   neutral     4629   0.659139  0.611579   \n",
       "32         SB10k                ANGST  positive     1717   0.335915  0.479907   \n",
       "33         SB10k              AffDict  negative     1130   0.315682  0.137168   \n",
       "34         SB10k              AffDict   neutral     4629   0.643587  0.734932   \n",
       "35         SB10k              AffDict  positive     1717   0.331960  0.328480   \n",
       "36         SB10k             AffNorms  negative     1130   0.486381  0.110619   \n",
       "37         SB10k             AffNorms   neutral     4629   0.689722  0.846619   \n",
       "38         SB10k             AffNorms  positive     1717   0.510085  0.456610   \n",
       "39         SB10k  Bayesian SentiMerge  negative     1130   0.460922  0.203540   \n",
       "40         SB10k  Bayesian SentiMerge   neutral     4629   0.693279  0.771009   \n",
       "41         SB10k  Bayesian SentiMerge  positive     1717   0.462548  0.492720   \n",
       "42         SB10k                  GPC  negative     1130   0.236152  0.430088   \n",
       "43         SB10k                  GPC   neutral     4629   0.650951  0.354936   \n",
       "44         SB10k                  GPC  positive     1717   0.322391  0.543390   \n",
       "45         SB10k               PolArt  negative     1130   0.283419  0.390265   \n",
       "46         SB10k               PolArt   neutral     4629   0.696220  0.425794   \n",
       "47         SB10k               PolArt  positive     1717   0.355131  0.638905   \n",
       "48         SB10k              SentiWS  negative     1130   0.293320  0.268142   \n",
       "49         SB10k              SentiWS   neutral     4629   0.669539  0.721754   \n",
       "50         SB10k              SentiWS  positive     1717   0.467309  0.395457   \n",
       "51         SB10k     Weighted Average  negative     1130   0.391566  0.230088   \n",
       "52         SB10k     Weighted Average   neutral     4629   0.684744  0.788291   \n",
       "53         SB10k     Weighted Average  positive     1717   0.469993  0.405941   \n",
       "\n",
       "          F1  AccuracyOverall   MacroF1  pos_thr  neg_thr  \n",
       "0   0.029159         0.605428  0.294234     0.10    -0.10  \n",
       "1   0.762923         0.605428  0.294234     0.10    -0.10  \n",
       "2   0.090621         0.605428  0.294234     0.10    -0.10  \n",
       "3   0.193671         0.458852  0.311815     0.10    -0.10  \n",
       "4   0.634197         0.458852  0.311815     0.10    -0.10  \n",
       "5   0.107577         0.458852  0.311815     0.10    -0.10  \n",
       "6   0.124387         0.511757  0.304942     0.10    -0.10  \n",
       "7   0.686905         0.511757  0.304942     0.10    -0.10  \n",
       "8   0.103534         0.511757  0.304942     0.10    -0.10  \n",
       "9   0.086979         0.514887  0.299153     0.10    -0.10  \n",
       "10  0.683372         0.514887  0.299153     0.10    -0.10  \n",
       "11  0.127108         0.514887  0.299153     0.10    -0.10  \n",
       "12  0.088011         0.617719  0.331793     0.10    -0.10  \n",
       "13  0.763702         0.617719  0.331793     0.10    -0.10  \n",
       "14  0.143665         0.617719  0.331793     0.10    -0.10  \n",
       "15  0.403640         0.374990  0.329138     0.10    -0.10  \n",
       "16  0.456542         0.374990  0.329138     0.10    -0.10  \n",
       "17  0.127233         0.374990  0.329138     0.10    -0.10  \n",
       "18  0.349291         0.453737  0.361707     0.10    -0.10  \n",
       "19  0.596046         0.453737  0.361707     0.10    -0.10  \n",
       "20  0.139785         0.453737  0.361707     0.10    -0.10  \n",
       "21  0.282174         0.592030  0.386125     0.10    -0.10  \n",
       "22  0.734423         0.592030  0.386125     0.10    -0.10  \n",
       "23  0.141779         0.592030  0.386125     0.10    -0.10  \n",
       "24  0.250103         0.525193  0.356046     0.10    -0.10  \n",
       "25  0.675624         0.525193  0.356046     0.10    -0.10  \n",
       "26  0.142410         0.525193  0.356046     0.10    -0.10  \n",
       "27  0.124444         0.574371  0.379527     0.10    -0.10  \n",
       "28  0.712749         0.574371  0.379527     0.10    -0.10  \n",
       "29  0.301388         0.574371  0.379527     0.10    -0.10  \n",
       "30  0.260495         0.521268  0.430056     0.10    -0.10  \n",
       "31  0.634469         0.521268  0.430056     0.10    -0.10  \n",
       "32  0.395204         0.521268  0.430056     0.10    -0.10  \n",
       "33  0.191240         0.551231  0.402561     0.10    -0.10  \n",
       "34  0.686233         0.551231  0.402561     0.10    -0.10  \n",
       "35  0.330211         0.551231  0.402561     0.10    -0.10  \n",
       "36  0.180245         0.645800  0.474091     0.15    -0.15  \n",
       "37  0.760159         0.645800  0.474091     0.15    -0.15  \n",
       "38  0.481868         0.645800  0.474091     0.15    -0.15  \n",
       "39  0.282382         0.621322  0.496540     0.10    -0.10  \n",
       "40  0.730081         0.621322  0.496540     0.10    -0.10  \n",
       "41  0.477157         0.621322  0.496540     0.10    -0.10  \n",
       "42  0.304893         0.409577  0.389655     0.10    -0.10  \n",
       "43  0.459388         0.409577  0.389655     0.10    -0.10  \n",
       "44  0.404684         0.409577  0.389655     0.10    -0.10  \n",
       "45  0.328369         0.469369  0.437767     0.10    -0.10  \n",
       "46  0.528418         0.469369  0.437767     0.10    -0.10  \n",
       "47  0.456513         0.469369  0.437767     0.10    -0.10  \n",
       "48  0.280166         0.578250  0.467741     0.15    -0.15  \n",
       "49  0.694667         0.578250  0.467741     0.15    -0.15  \n",
       "50  0.428391         0.578250  0.467741     0.15    -0.15  \n",
       "51  0.289855         0.616105  0.486119     0.15    -0.15  \n",
       "52  0.732878         0.616105  0.486119     0.15    -0.15  \n",
       "53  0.435625         0.616105  0.486119     0.15    -0.15  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "# Benchmark dataset paths\n",
    "GERMEVAL_PATH = \"../evaluation_datasets/GermEval2017/GermEval2017.tsv\"  \n",
    "SB10K_PATH    = \"../evaluation_datasets/SB10k/SB10k.tsv\"                \n",
    "\n",
    "# Lexicon files\n",
    "LEXICON_VARIANTS = [\n",
    "    {\"name\": \"Weighted Average\",    \"path\": \"aggregated_sentiment_scores_.csv\", \"score_col\": \"weighted_avg_score\"},\n",
    "    {\"name\": \"Bayesian SentiMerge\", \"path\": \"SentiMerge_score_light.csv\",       \"score_col\": \"senti_merge_score\"},\n",
    "    {\"name\": \"AffNorms\", \"path\": \"sentiment_lexika_scaled_final.csv\",       \"score_col\": \"AffNorms_Val_scaled\"},\n",
    "    {\"name\": \"SentiWS\", \"path\": \"sentiment_lexika_scaled_final.csv\",       \"score_col\":              \"SentiWS\"},\n",
    "    {\"name\": \"PolArt\", \"path\": \"sentiment_lexika_scaled_final.csv\",       \"score_col\":           \"PolArt_num\"},\n",
    "    {\"name\": \"GPC\", \"path\": \"sentiment_lexika_scaled_final.csv\",       \"score_col\": \n",
    "     \"GPC_num\"},\n",
    "    {\"name\": \"ALPIN\", \"path\": \"sentiment_lexika_scaled_final.csv\",       \"score_col\": \"ALPIN_sentiment_scaled\"},\n",
    "    {\"name\": \"ANGST\", \"path\": \"sentiment_lexika_scaled_final.csv\",       \"score_col\":  \"ANGST_Valence_scaled\"},\n",
    "    {\"name\": \"AffDict\", \"path\": \"sentiment_lexika_scaled_final.csv\",       \"score_col\": \"AffDict_Eval_scaled\"},\n",
    "]\n",
    "\n",
    "# Benchmark column names\n",
    "GE_TEXT_COL, GE_LABEL_COL = \"Text\", \"Sentiment\"\n",
    "SB_TEXT_COL, SB_LABEL_COL = \"Normalized\", \"Sentiment\"  \n",
    "\n",
    "\n",
    "# static thresholds for 3-way classification (pos, neg, neutral)\n",
    "STATIC_THRESHOLDS: Dict[str, Dict[str, Tuple[float,float]]] = {\n",
    "    \"SB10k\": {\n",
    "        \"Weighted Average\":    ( 0.15, -0.15),\n",
    "        \"Bayesian SentiMerge\": ( 0.1, -0.1),\n",
    "        \"AffNorms\":            ( 0.15, -0.15),\n",
    "        \"SentiWS\":             ( 0.15, -0.15),\n",
    "        \"PolArt\":              ( 0.1, -0.1),\n",
    "        \"GPC\":                 ( 0.1, -0.1),\n",
    "        \"ALPIN\":               ( 0.1, -0.1),\n",
    "        \"ANGST\":               ( 0.1, -0.1),\n",
    "        \"AffDict\":             ( 0.1, -0.1),\n",
    "    },\n",
    "    \"GermEval2017\": {\n",
    "        \"Weighted Average\":    ( 0.1, -0.1),\n",
    "        \"Bayesian SentiMerge\": ( 0.1, -0.1),\n",
    "        \"AffNorms\":            ( 0.1, -0.1),\n",
    "        \"SentiWS\":             ( 0.1, -0.1),\n",
    "        \"PolArt\":              ( 0.1, -0.1),\n",
    "        \"GPC\":                 ( 0.1, -0.1),\n",
    "        \"ALPIN\":               ( 0.1, -0.1),\n",
    "        \"ANGST\":               ( 0.1, -0.1),\n",
    "        \"AffDict\":             ( 0.1, -0.1),\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Heuristics with switches \n",
    "USE_NEGATION = True\n",
    "USE_INTENSIFIERS = True\n",
    "# how many tokens after a negation to flip\n",
    "NEGATION_SCOPE = 3\n",
    "\n",
    "# Borrowed from https://github.com/KarstenAMF/GerVADER/tree/master\n",
    "INTENSIFIERS = {\n",
    "    # intensifier\n",
    "    \"sehr\": 1.5, \"extrem\": 1.7, \"unglaublich\": 1.6, \"total\": 1.4, \"mega\": 1.5, \"wirklich\": 1.3,\n",
    "    # weakener\n",
    "    \"ziemlich\": 1.2, \"recht\": 1.15, \"relativ\": 1.15, \"etwas\": 1.1, \"leicht\": 1.1\n",
    "}\n",
    "DOWNTONERS = {\n",
    "    \"kaum\": 0.7, \"wenig\": 0.8, \"einigermaÃŸen\": 0.85, \"teilweise\": 0.9, \"bisschen\": 0.9\n",
    "}\n",
    "NEGATIONS = {\"nicht\",\"nie\",\"keine\",\"kein\",\"keiner\",\"keines\",\"keinem\",\"keinen\",\"ohne\",\"nichts\"}\n",
    "\n",
    "# \"mean\" is robust; \"sum\" would also work with different thresholds\n",
    "AGG_MODE = \"mean\"   \n",
    "\n",
    "\n",
    "# Minimal-Tokenizer + stopwords\n",
    "USE_STOPWORDS = True\n",
    "STOPWORDS = {\n",
    "    \"der\",\"die\",\"das\",\"ein\",\"eine\",\"einen\",\"einem\",\"einer\",\"eines\",\n",
    "    \"und\",\"oder\",\"aber\",\"denn\",\"nur\",\"auch\",\"so\",\"wie\",\"als\",\n",
    "    \"zu\",\"von\",\"mit\",\"auf\",\"in\",\"im\",\"am\",\"um\",\"fÃ¼r\",\"an\",\"bei\",\"aus\",\n",
    "    \"ich\",\"du\",\"er\",\"sie\",\"es\",\"wir\",\"ihr\",\n",
    "    \"mich\",\"dich\",\"ihn\",\"uns\",\"euch\",\n",
    "    \"ist\",\"bin\",\"bist\",\"sind\",\"seid\",\"war\",\"waren\",\"werden\",\"wird\",\"sein\",\"hat\",\"haben\",\"habe\",\"hatte\",\"hatten\",\n",
    "    \"man\",\"sich\",\"noch\",\"schon\",\"mal\"\n",
    "}\n",
    "\n",
    "SPLIT_RE = re.compile(r\"[^\\wÃ¤Ã¶Ã¼Ã„Ã–ÃœÃŸ]+\", flags=re.UNICODE)\n",
    "\n",
    "def simple_tokens(text: str) -> List[str]:\n",
    "    if not isinstance(text, str): \n",
    "        return []\n",
    "    t = text.lower()\n",
    "    toks = [tok for tok in SPLIT_RE.split(t) if tok]\n",
    "    if USE_STOPWORDS:\n",
    "        toks = [tok for tok in toks if tok not in STOPWORDS]\n",
    "    return toks\n",
    "\n",
    "\n",
    "# Emoji-/Emoticon-list\n",
    "EMOJI_SCORES = {\n",
    "    \"ðŸ™‚\": 0.4, \"ðŸ˜Š\": 0.5, \"ðŸ˜\": 0.6, \"ðŸ˜‚\": 0.5, \"ðŸ¤£\": 0.5, \"ðŸ˜\": 0.6, \"â¤ï¸\": 0.6, \"â¤\": 0.6,\n",
    "    \":)\": 0.4, \":-)\": 0.4,\n",
    "    \"ðŸ˜¡\": -0.6, \"ðŸ¤¬\": -0.7, \"ðŸ˜ \": -0.5, \"ðŸ˜¢\": -0.5, \"ðŸ˜­\": -0.6,\n",
    "    \":(\": -0.4, \":-(\": -0.4,\n",
    "    \"ðŸ‘\": 0.4, \"ðŸ‘Ž\": -0.4\n",
    "}\n",
    "\n",
    "def emoji_scores_from_text(text: str) -> List[float]:\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    t = text  # not lowercased; emojis are case-independent; emoticons are still recognized\n",
    "    scores = []\n",
    "    for sym, sc in EMOJI_SCORES.items():\n",
    "        # simple frequency counting\n",
    "        cnt = t.count(sym)\n",
    "        if cnt > 0:\n",
    "            scores.extend([sc] * cnt)\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Utilities\n",
    "def load_lexicon(path: str, score_col: str) -> Dict[str, float]:\n",
    "    df = pd.read_csv(path)\n",
    "    if score_col not in df.columns:\n",
    "        raise AssertionError(f\"Spalte {score_col} fehlt in {path}\")\n",
    "    return (\n",
    "        df[[\"Wort\", score_col]]\n",
    "        .dropna(subset=[score_col])\n",
    "        .assign(Wort=lambda x: x[\"Wort\"].astype(str).str.strip().str.lower())\n",
    "        .set_index(\"Wort\")[score_col]\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "def apply_heuristics(tokens: List[str], base_scores: List[float]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Intensifiers/downtoners scale the magnitude of the NEXT sentiment-bearing token.\n",
    "    Negation flips the sign of the next sentiment-bearing tokens within the scope\n",
    "    \"\"\"\n",
    "    scores = base_scores.copy()\n",
    "    n = len(tokens)\n",
    "\n",
    "    if USE_INTENSIFIERS:\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            tok = tokens[i]\n",
    "            mult = INTENSIFIERS.get(tok) or DOWNTONERS.get(tok)\n",
    "            if mult is not None:\n",
    "                for j in range(i + 1, n):\n",
    "                    if scores[j] != 0.0:\n",
    "                        scores[j] = np.sign(scores[j]) * min(1.0, abs(scores[j]) * mult)\n",
    "                        break\n",
    "            i += 1\n",
    "\n",
    "    if USE_NEGATION:\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            if tokens[i] in NEGATIONS:\n",
    "                for j in range(i + 1, min(n, i + 1 + NEGATION_SCOPE)):\n",
    "                    if scores[j] != 0.0:\n",
    "                        scores[j] = -scores[j]\n",
    "                i += NEGATION_SCOPE\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    return scores\n",
    "\n",
    "def score_text(text: str, w2s: Dict[str, float], mode: str = \"mean\") -> float:\n",
    "    # (1) regular token scoring\n",
    "    toks = simple_tokens(text)\n",
    "    raw = [w2s.get(t, 0.0) for t in toks]\n",
    "    adj = apply_heuristics(toks, raw)\n",
    "    vals = [v for v in adj if v != 0.0]\n",
    "    # (2) add emoji scores (as additional â€œtokensâ€)\n",
    "    vals.extend(emoji_scores_from_text(text))\n",
    "    if not vals:\n",
    "        return 0.0\n",
    "    return float(np.mean(vals) if mode == \"mean\" else np.sum(vals))\n",
    "\n",
    "def predict_label(score: float, pos_thr: float, neg_thr: float) -> str:\n",
    "    if score >= pos_thr:\n",
    "        return \"positive\"\n",
    "    if score <= neg_thr:\n",
    "        return \"negative\"\n",
    "    return \"neutral\"\n",
    "\n",
    "\n",
    "# Metriken\n",
    "def metrics_full(y_true: List[str], y_pred: List[str]) -> dict:\n",
    "    labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "    def prf(lbl):\n",
    "        tp = sum((yt == lbl) and (yp == lbl) for yt, yp in zip(y_true, y_pred))\n",
    "        fp = sum((yt != lbl) and (yp == lbl) for yt, yp in zip(y_true, y_pred))\n",
    "        fn = sum((yt == lbl) and (yp != lbl) for yt, yp in zip(y_true, y_pred))\n",
    "        sup = sum(yt == lbl for yt in y_true)\n",
    "        P = tp/(tp+fp) if (tp+fp) else 0.0\n",
    "        R = tp/(tp+fn) if (tp+fn) else 0.0\n",
    "        F1= 2*P*R/(P+R) if (P+R) else 0.0\n",
    "        return P, R, F1, sup\n",
    "    per = {lbl: prf(lbl) for lbl in labels}\n",
    "    macro_f1 = float(np.mean([per[l][2] for l in labels]))\n",
    "    acc = float(np.mean([yt==yp for yt, yp in zip(y_true,y_pred)]))\n",
    "    return {\"accuracy\": acc, \"macro_f1\": macro_f1, \"per_class\": per}\n",
    "\n",
    "# Evaluation with metrics\n",
    "def eval_tsv_static(tsv_path: str, text_col: str, label_col: str,\n",
    "                    w2s: Dict[str, float], dataset_name: str, variant_name: str,\n",
    "                    agg_mode: str = \"mean\") -> dict:\n",
    "    df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "    if text_col not in df.columns and \"Text\" in df.columns:\n",
    "        text_col = \"Text\"\n",
    "    df = df[[text_col, label_col]].dropna()\n",
    "\n",
    "    # Scores\n",
    "    df[\"__score__\"] = df[text_col].apply(lambda x: score_text(x, w2s, mode=agg_mode))\n",
    "\n",
    "    # Thresholds\n",
    "    try:\n",
    "        pos_thr, neg_thr = STATIC_THRESHOLDS[dataset_name][variant_name]\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"Keine statischen Thresholds fÃ¼r dataset={dataset_name}, variant={variant_name}\")\n",
    "\n",
    "    # Predictions + metrics\n",
    "    preds = [predict_label(s, pos_thr, neg_thr) for s in df[\"__score__\"].values]\n",
    "    m = metrics_full(df[label_col].tolist(), preds)\n",
    "\n",
    "    return {\"n\": len(df), \"pos_thr\": pos_thr, \"neg_thr\": neg_thr, \"metrics\": m}\n",
    "\n",
    "\n",
    "# Run-through: all variants Ã— both datasets\n",
    "rows_long = []    # measurements per class\n",
    "\n",
    "for variant in LEXICON_VARIANTS:\n",
    "    try:\n",
    "        w2s = load_lexicon(variant[\"path\"], variant[\"score_col\"])\n",
    "    except AssertionError as e:\n",
    "        print(f\"Ãœberspringe {variant['name']}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for ds_name, (path, text_col, label_col) in {\n",
    "        \"GermEval2017\": (GERMEVAL_PATH, GE_TEXT_COL, GE_LABEL_COL),\n",
    "        \"SB10k\":        (SB10K_PATH,     SB_TEXT_COL, SB_LABEL_COL),\n",
    "    }.items():\n",
    "        res = eval_tsv_static(path, text_col, label_col, w2s,\n",
    "                              dataset_name=ds_name, variant_name=variant[\"name\"], agg_mode=AGG_MODE)\n",
    "        acc = res[\"metrics\"][\"accuracy\"]\n",
    "        mF1 = res[\"metrics\"][\"macro_f1\"]\n",
    "        pt, nt = res[\"pos_thr\"], res[\"neg_thr\"]\n",
    "\n",
    "        # expand per class\n",
    "        for cls, (P,R,F1,S) in res[\"metrics\"][\"per_class\"].items():\n",
    "            rows_long.append({\n",
    "                \"Dataset\": ds_name,\n",
    "                \"Variant\": variant[\"name\"],\n",
    "                \"Class\": cls,\n",
    "                \"Support\": S,\n",
    "                \"Precision\": P,\n",
    "                \"Recall\": R,\n",
    "                \"F1\": F1,\n",
    "                \"AccuracyOverall\": acc,\n",
    "                \"MacroF1\": mF1,\n",
    "                \"pos_thr\": pt, \"neg_thr\": nt\n",
    "            })\n",
    "\n",
    "        res.update({\"Dataset\": ds_name, \"Variant\": variant[\"name\"]})\n",
    "\n",
    "# Final results table\n",
    "results_table = pd.DataFrame(rows_long).sort_values(by=[\"Dataset\",\"Variant\",\"Class\"]).reset_index(drop=True)\n",
    "results_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec15e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SB10k  |  Gold-Label: positive\n",
      "Post/Tweet: RT @TheKedosZone : so eine Hearthstone - Key von @BlizzardCSEU_EN fÃ¼r die nett YouTube - Onkel Kedos sein auch schon was ganz fein . * hust * \n",
      "\n",
      "Tokens mit Scores:\n",
      "Token           Weighted Avg  Bayes-light\n",
      "rt                     0.095        0.044\n",
      "key                    0.078        0.036\n",
      "nett                   0.652        0.544\n",
      "youtube                0.010        0.015\n",
      "onkel                  0.269        0.289\n",
      "ganz                   0.330        0.145\n",
      "fein                   0.652        0.398\n",
      "\n",
      "Berechnung:\n",
      "  Weighted Avg : 0.298 â†’ positive (Thr +0.15/-0.15)\n",
      "  Bayes-light  : 0.210 â†’ positive (Thr +0.10/-0.10)\n",
      "================================================================================\n",
      "GermEval2017  |  Gold-Label: positive\n",
      "Post/Tweet: Bahn: Streik endet vorzeitig Der Streik der Gewerkschaft Deutscher LokomotivfÃ¼hrer (GDL) endet am 21. Mai um 19 Uhr. Die Gewerkschaft und die Deutsche Bahn haben sich auf die tariflichen Grundlagen fÃ¼r einen FlÃ¤chentarifvertrag fÃ¼r das Zugpersonal und gleichzeitig auf ein Schlic \n",
      "\n",
      "Tokens mit Scores:\n",
      "Token           Weighted Avg  Bayes-light\n",
      "bahn                   0.007        0.004\n",
      "streik                -0.491       -0.339\n",
      "vorzeitig             -0.422       -0.168\n",
      "streik                -0.491       -0.339\n",
      "gewerkschaft          -0.076       -0.073\n",
      "deutscher              0.126        0.099\n",
      "lokomotivfÃ¼hrer       -0.009       -0.004\n",
      "mai                    0.035       -0.002\n",
      "uhr                    0.083        0.076\n",
      "gewerkschaft          -0.076       -0.073\n",
      "deutsche              -0.014        0.009\n",
      "bahn                   0.007        0.004\n",
      "flÃ¤chentarifvertrag       -0.228       -0.106\n",
      "zugpersonal           -0.095       -0.044\n",
      "gleichzeitig           0.152        0.073\n",
      "\n",
      "Berechnung:\n",
      "  Weighted Avg : -0.099 â†’ neutral (Thr +0.10/-0.10)\n",
      "  Bayes-light  : -0.059 â†’ neutral (Thr +0.10/-0.10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def showcase_example(dataset, path, text_col, label_col):\n",
    "    # loading\n",
    "    w2s_avg  = load_lexicon(\"aggregated_sentiment_scores_.csv\", \"weighted_avg_score\")\n",
    "    w2s_bayes= load_lexicon(\"SentiMerge_score_light.csv\", \"senti_merge_score\")\n",
    "\n",
    "    # Thresholds\n",
    "    pos_avg, neg_avg   = STATIC_THRESHOLDS[dataset][\"Weighted Average\"]\n",
    "    pos_b, neg_b       = STATIC_THRESHOLDS[dataset][\"Bayesian SentiMerge\"]\n",
    "\n",
    "    # Example post\n",
    "    df   = pd.read_csv(path, sep=\"\\t\").dropna(subset=[text_col,label_col])\n",
    "    row  = df.iloc[0]\n",
    "    text, gold = str(row[text_col]), str(row[label_col])\n",
    "\n",
    "    # tokenize\n",
    "    toks = simple_tokens(text)\n",
    "\n",
    "    # get scores\n",
    "    avg_scores  = [w2s_avg.get(t,0.0) for t in toks]\n",
    "    bayes_scores= [w2s_bayes.get(t,0.0) for t in toks]\n",
    "\n",
    "    # only tokens with at least one non-zero score\n",
    "    tok_table = [(t,a,b) for t,a,b in zip(toks,avg_scores,bayes_scores) if (a!=0.0 or b!=0.0)]\n",
    "\n",
    "    # aggregate\n",
    "    vals_avg   = [a for _,a,_ in tok_table if a!=0.0]\n",
    "    vals_bayes = [b for _,_,b in tok_table if b!=0.0]\n",
    "    agg_avg    = sum(vals_avg)/len(vals_avg) if vals_avg else 0.0\n",
    "    agg_bayes  = sum(vals_bayes)/len(vals_bayes) if vals_bayes else 0.0\n",
    "\n",
    "    pred_avg   = predict_label(agg_avg,pos_avg,neg_avg)\n",
    "    pred_bayes = predict_label(agg_bayes,pos_b,neg_b)\n",
    "\n",
    "    # output\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{dataset}  |  Gold-Label: {gold}\")\n",
    "    print(\"Post/Tweet:\", text, \"\\n\")\n",
    "    print(\"Tokens mit Scores:\")\n",
    "    print(f\"{'Token':15s} {'Weighted Avg':>12s} {'Bayes-light':>12s}\")\n",
    "    for t,a,b in tok_table:\n",
    "        print(f\"{t:15s} {a:12.3f} {b:12.3f}\")\n",
    "    print(\"\\nBerechnung:\")\n",
    "    print(f\"  Weighted Avg : {agg_avg:.3f} â†’ {pred_avg} (Thr {pos_avg:+.2f}/{neg_avg:+.2f})\")\n",
    "    print(f\"  Bayes-light  : {agg_bayes:.3f} â†’ {pred_bayes} (Thr {pos_b:+.2f}/{neg_b:+.2f})\")\n",
    "\n",
    "# Showcase for one example post from each dataset\n",
    "showcase_example(\"SB10k\", SB10K_PATH, SB_TEXT_COL, SB_LABEL_COL)\n",
    "showcase_example(\"GermEval2017\", GERMEVAL_PATH, GE_TEXT_COL, GE_LABEL_COL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
